#!/bin/bash
#
# Provide a wrapper for starting the workflow process via Docker.
# Wrapper will create a dynamic Nextflow inputs.json file.
#
# Exit Codes:
# 1  -- no or invalid options passed - general error.
# 5  -- needs either --runFolder or --fastqFolder 
# 6  -- an input folder is not a directory, does not exist, or has wrong permissions.
# 7  -- specified config file does not exist.
# 8  -- mount permission errors on docker.  try not using a network mount.
# 9 -- dragen is not installed or wrong dragen version is installed
# 10 -- attempt to run without a runFolder.
# 11 -- not enough available disk space for analaysis output.
# 12 -- existing dragen process or workflow docker container running.  
# 13 -- missing CopyComplete.txt file in run folder. 
# 14 -- user can't run docker 
# 15 -- invalid/expired/missing DRAGEN license 
# 16 -- passed wrong combination of runFolder and fastqFolder
##

# TODO : Check that all the binding paths match the Nextflow formats

# Environment variables generated by Makefile command
PRODUCT_NAME=DRAGEN_TruSight_Oncology_500_ctDNA;
DOCKER_IMAGE=dragen_tso500_ctdna;

# Representing the internal or marketing version
# depending on whether this is dev or prod (respectively).
UNIFIED_VERSION=2.1.1;

# Set the minimum dragen version
MIN_DRAGEN_VERSION=3.10.9;

# define short long option flags:
TEMP=`getopt -o h --long help,noRemove,ignoreDiskCheck,version,dev,license:,executionContext:,fastqFolder:,firstTileOnly:,runFolder:,sampleSheet:,analysisFolder:,resourcesFolder:,sampleIDs:,ignoreDragenCheck,a\
             -n '${PRODUCT_NAME}.sh' -- "$@"`
if [ $? != 0 ] ; then echo "Terminating..." >&2 ; exit 1 ; fi

# quotes around $TEMP are required
eval set -- "$TEMP"

RUN_UID=${PRODUCT_NAME}_Analysis_$(date +%Y%m%d_%H%M%S)
ANALYSIS_FOLDER_IN_CONTAINER="/opt/illumina/analysis-folder"
SAMPLESHEET_IN_CONTAINER="/opt/illumina/SampleSheet.csv"
# TODO /staging needs to be set dynamically based on the host variable
DEFAULT_RESOURCES_FOLDER="/staging/illumina/${PRODUCT_NAME}/resources"
RESOURCES_FOLDER_IN_CONTAINER="/opt/illumina/resources"
FASTQ_FOLDER_IN_CONTAINER="/opt/illumina/fastq-folder"
RUN_FOLDER_IN_CONTAINER="/opt/illumina/run-folder"
INPUT_FILE_IN_CONTAINER="${ANALYSIS_FOLDER_IN_CONTAINER}/params.json"
RESOURCE_FILE_CHECK="TST500C_manifest.txt"
USER_ID=
RUN_FOLDER=
ANALYSIS_FOLDER=
RESOURCES_FOLDER=
FASTQ_FOLDER=
SAMPLESHEET_SRC=
SAMPLE_IDS=
IS_NOVA_SEQ=
FIRST_TILE_ONLY=
IS_SHOWING_ART=
EXECUTION_CONTEXT=local
#MIN_SPACE=3000
EMPTY_VALUE="\"\""
IS_IGNORING_SPACE_CHECK=
PHASE3_CONFIG_PATH=/opt/illumina/nextflow_phase3_server.config
PHASE4_CONFIG_PATH=/opt/illumina/nextflow_phase4_server.config
INTERMEDIATE_SAMPLE_IDS="intermediate_sample_ids.json"
INTERMEDIATE_SAMPLE_IDS_FOLDER="/staging/tmp"
INTERMEDIATE_SAMPLE_ID_FILE="${INTERMEDIATE_SAMPLE_IDS_FOLDER}/${INTERMEDIATE_SAMPLE_IDS}"

# Minimum space for each config
declare -A MIN_SPACE_MAP
MIN_SPACE_MAP["NEXTSEQ"]=500
MIN_SPACE_MAP["NOVASEQ-SP"]=500
MIN_SPACE_MAP["NOVASEQ-S1"]=1000
MIN_SPACE_MAP["NOVASEQ-S2"]=1500
MIN_SPACE_MAP["NOVASEQ-S4"]=4000

function help() {
  cat <<-EOF
    ${PRODUCT_NAME}.sh [options]

    -h| --help           This help screen.
    --runFolder          REQUIRED if no fastqFolder is specified. INVALID if fastqFolder is specified. Provide the full path to the run folder.
    --fastqFolder        Optional, REQUIRED if no runFolder is specified. INVALID if runFolder is specified. Provide the full path to the FASTQ folder
                         and analysis will start here.
    --analysisFolder     Optional. Provide the full path to analysis folder.
                         Folder MUST have sufficient space (min ${MIN_SPACE} GB free)
                         and MUST be on an NVMe SSD drive to ensure 
                         performance. Default location is
                         /staging/${PRODUCT_NAME}_Analysis_<timestamp>.
    --sampleIDs          Optional. Provide the comma delimited Sample IDs that
                         should be processed on this node,
                         e.g.: "Sample_1,Sample_2" or for 1 sample : "Single_Sample"
                         If flag is omitted, all samples are used.
    --sampleSheet        Optional. Provide the full path, including file name,
                         to the SampleSheet.csv to use if not located in
                         runFolder.
    --version            Displays the version of the workflow and exits.

EOF
  exit
}

# TODO : Check flags by flag name. Doesn't rely on specific order.
# identify flags and set options.
while true; do
  case "$1" in
    -h | --help       ) help ;;
    --dev             ) DEV=true                 ; shift   ;;
    --user            ) USER_ID="$2"             ; shift 2 ;;
    --noRemove        ) NO_REMOVE_CONTAINER=1    ; shift   ;;
    --version         ) echo "Version: ${UNIFIED_VERSION}"; exit ;;
    --license         ) LICENSE="$2"             ; shift 2 ;;
    --sampleIDs       ) SAMPLE_IDS="$2"          ; shift 2 ;;
    --runFolder       ) RUN_FOLDER="$2"          ; shift 2 ;;
    --sampleSheet     ) SAMPLESHEET="$2"         ; shift 2 ;;
    --fastqFolder     ) FASTQ_FOLDER="$2"        ; shift 2 ;;
    --analysisFolder  ) ANALYSIS_FOLDER="$2"     ; shift 2 ;;
    --resourcesFolder ) RESOURCES_FOLDER="$2"    ; shift 2 ;;
    --executionContext ) EXECUTION_CONTEXT="$2"  ; shift 2 ;;
    # Remove In final release
    --firstTileOnly   ) FIRST_TILE_ONLY="$2"     ; shift 2 ;;
    --ignoreDragenCheck ) DRAGEN_CHECK="true"    ; shift   ;;
    --ignoreDiskCheck )  IS_IGNORING_SPACE_CHECK=true ; shift ;;
    -- ) shift; break ;;
    * ) break ;;
  esac
done

#check_user

ENGINE_BIND_PREFIX=" -v"
ENGINE_BIND_SUFFIX=":rw"
ENGINE_BIND_SUFFIX_RO=":ro"
ENGINE_CMD=" docker run -t "
ENGINE_CMD_SUFFIX="${DOCKER_IMAGE}:${UNIFIED_VERSION}"
ENGINE_CMD_EDICO="${ENGINE_BIND_PREFIX} /var/log/dragen:/var/log/dragen \
    ${ENGINE_BIND_PREFIX} /var/lib/edico:/var/lib/edico \
    ${ENGINE_BIND_PREFIX} /var/run/dragen:/var/run/dragen \
    ${ENGINE_BIND_PREFIX} /dev/log:/dev/log \
    ${ENGINE_BIND_PREFIX} /dev/hugepages:/dev/hugepages \
    ${ENGINE_BIND_PREFIX} /dev/shm:/dev/shm "
ENGINE_CMD_DEVICE="--device /dev/bus \
    --pid host \
    --ulimit memlock=-1 \
    --ulimit nofile=65535:65535 \
    --ulimit nproc=16400:16420 "
ENGINE_CMD+=" ${ENGINE_CMD_DEVICE} "

checkDragenVersion() {
  [ ! -z "$DRAGEN_CHECK" ] && return

 # DRAGEN="/opt/edico/bin/dragen"
  DRAGEN="/opt/edico/bin/dragen"
  DRAGEN_INFO="/opt/edico/bin/dragen_info"
  if [ ! -e ${DRAGEN} ] || [ ! -e ${DRAGEN_INFO} ]; then
    echo -e "DRAGEN is not installed.  Please reinstall DRAGEN TSO500 ctDNA."
    exit 9
  fi

  DRAGEN_INFO="${DRAGEN_INFO} -b"

  # Example: 07.021.624.3.10.1-136
  FULL_DRAGEN_SW_VERSION=$(${DRAGEN_INFO} | grep 'Software Version:' | cut -d : -f 2 | tr -d '[:space:]' | cut -d - -f 1-2)
  # Example: 3.10.10
  DRAGEN_SW_VERSION=$(echo -e ${FULL_DRAGEN_SW_VERSION} | cut -d . -f 4-6)
  # Example: 3.10
  DRAGEN_MAJOR_MINOR_VERSION=$(echo -e ${DRAGEN_SW_VERSION} | cut -d . -f 1-2)
  # Example: 1
  DRAGEN_BUILD_VERSION=$(echo -e ${DRAGEN_SW_VERSION} | cut -d . -f 3 | cut -d - -f 1 )

  REQD_DRAGEN_MAJOR_MINOR_VERSION=$(echo -e ${MIN_DRAGEN_VERSION} | cut -d . -f 1-2)
  REQD_DRAGEN_BUILD_VERSION=$(echo -e ${MIN_DRAGEN_VERSION} | cut -d . -f 3 )

  ERROR=""

  # Verify MAJOR.MINOR version (ie - 3.10)
  if [ "${DRAGEN_MAJOR_MINOR_VERSION}" != "${REQD_DRAGEN_MAJOR_MINOR_VERSION}" ]; then
    ERROR="Current DRAGEN version is ${DRAGEN_SW_VERSION}.  Version ${REQD_DRAGEN_MAJOR_MINOR_VERSION}.X is required (where X >= ${REQD_DRAGEN_BUILD_VERSION})."
  fi
  # Verify that build is not less than the minimum build version
  if [ -z "${ERROR}" ] && [ ${DRAGEN_BUILD_VERSION} -lt ${REQD_DRAGEN_BUILD_VERSION} ]; then
    ERROR="Current DRAGEN version is ${DRAGEN_SW_VERSION}.  Version ${REQD_DRAGEN_MAJOR_MINOR_VERSION}.X is required (where X >= ${REQD_DRAGEN_BUILD_VERSION})."
  fi

  if [ ! -z "${ERROR}" ]; then
    echo ${ERROR}
    exit 9
  fi
}
# Check if using NovaSeq
# WARNING: xq call sends error messages to null, be wary if receiving silent failures.
function checkIsNovaSeq() {

    local is_novaseq=false;

    if [[ -z "${FASTQ_FOLDER}" ]] ; then

      local app_name=$( xmllint --xpath 'string(RunParameters/Application)' "${RUN_FOLDER}/RunParameters.xml" );
      
      if [[ "${app_name}" == "NovaSeq Control Software" ]]; then 
        is_novaseq=true
      fi 
    fi

    echo "$is_novaseq"
}

# Get the FLowcell mode
# $1 string, runParameters.xml path
function getFlowCellType() {
    local flowcell_type=$( xmllint --xpath 'string(RunParameters/RfidsInfo/FlowCellMode)' "${RUN_FOLDER}/RunParameters.xml" );

    echo "$flowcell_type"
}

# Get the space requirements for the given configuration.
# $1 - boolean, is NovaSeq
# $2 - string, Flowcell Mode
function getSpaceRequirement() {

    local key="NEXTSEQ"
    
    if [ $1 == true ]; 
    then
      key="NOVASEQ-${2}"
    fi

    local SPACE_REQ="${MIN_SPACE_MAP[${key}]}"
    echo "$SPACE_REQ"
}

# Test if minimum space available given environment information.
function checkDiskSpace() {
  local is_novaseq=$(checkIsNovaSeq )
  local flowcell_type=$(getFlowCellType )
  local min_space=$(getSpaceRequirement $is_novaseq $flowcell_type) 
  
  # verify analysis folder disk has minimum amount of free space
  local free_space=$(df --block-size=1G "${ANALYSIS_FOLDER}" | tail -1 | awk '{print $4}')

  if [[ "${IS_IGNORING_SPACE_CHECK}" != true ]] && (($free_space < $min_space)); then
    echo
    echo "There is not enough available disk space on folder ${ANALYSIS_FOLDER} under `dirname ${ANALYSIS_FOLDER}`. ${min_space}G disk space required, ${free_space}G is currently free."
    echo "Please move or remove old analysis output."
    exit 11
  fi
}

#
# $1 should be the directory to check.
#
function checkDirectory() {
  if [ ! -d $1 ]; then
    echo "Sorry, $1 needs to be an existing directory."
    exit 6
  else
    fs_type=`stat --file-system --format=%T $1`
    disk=`df $1|grep -vi filesystem`
    writeReceipt "File system type:" $fs_type:$1
    writeReceipt "Disk and usage:  " $disk
 fi
}

#
# $1 should be the directory to check.
#
function checkDirectoryAndPermissions() {

  checkDirectory $1

  if [ ! -r $1 ]; then
    echo "Error - cannot read \"$1\" - permission denied"
    exit 6
  elif [ ! -x $1 ]; then
    echo "Error - \"$1\" requires execute permissions"
    exit 6
  fi

}

# check the directory resides on the local nvme disk
function checkDirectoryDisk() {
  checkDirectory $1
  disk_check=`df $1|grep "/dev/nvm"`
    result=$?
    if [ "${result}" -ne 0 ]; then
      echo -e "\nError - $1 should be pointing to a path on a local disk"
      exit 8
    fi
}

# check that an input file exists,  $1 should be the file to check
#
function checkFile() {
  if [ ! -f $1 ]; then
    echo "Sorry, $1 needs to be an existing file."
    exit 7
  fi
  if [ ! -r $1 ]; then
    echo "Error - cannot read $1 - permission denied"
    exit 6
  fi
}

# write to the input file.
function writeInputFile() {
 echo "  "$1 >> "$INPUT_FILE"
}

function writeReceipt() {
  echo "$1: ${@:2}" >> "$RECEIPT"
}

function cleanupOnSignal() {
    echo "Exiting early on signal"
    CONTAINER_RUNNING=$(docker ps | grep ${DOCKER_IMAGE} | awk '{print $1}')
    [ -n "${CONTAINER_RUNNING}" ] && docker stop ${CONTAINER_RUNNING}
    exit 1
}

# Checks for the right combination of runFolder and fastqFolder flags
function checkRunAndFastQFlags() {

  if [[ ! -z "${RUN_FOLDER}" ]] && [[ ! -z "${FASTQ_FOLDER}" ]] ; then

    echo "Run Folder : ${RUN_FOLDER}"
    echo "FASTQ Folder : ${FASTQ_FOLDER}";
    echo "--runFolder and --fastqFolder can't be specified at the same time. Please only choose one.";
    exit 16;
  
  elif [[ -z "${RUN_FOLDER}" ]] && [[ -z "${FASTQ_FOLDER}" ]] ; then
    echo "Either --runFolder or --fastqFolder should be specified. Please choose one."
    exit 5;
  fi

}

# Verify that run folder and fastq folders aren't set at the same time
# This caused errors in the Dragen Analysis Caller stage
checkRunAndFastQFlags

# sanity checks
if [[ "$EUID" -ne 0 ]]; then
   if ! id -Gn | grep -qw docker
   then
       echo "$USER is not a member of group docker (needed to run docker)!"
       exit 14
   fi
fi

DRAGEN_RUNNING=$(ps axco command | egrep ^dragen\$)
[ -n "${DRAGEN_RUNNING}" ] && echo "A dragen process already appears to be running!" && exit 12;

CONTAINER_RUNNING=$(docker ps | grep ${DOCKER_IMAGE})
[ -n "${CONTAINER_RUNNING}" ] && echo "A docker container for this pipeline already appears to be running!" && exit 12;

echo "Checking dragen version..."
checkDragenVersion
/opt/edico/bin/dragen_reset

if ! /opt/edico/bin/dragen_lic -X -f TSO500Combined > /dev/null
then 
    echo "Invalid, missing, or expired DRAGEN license!" 
    exit 15
fi

# remove any exited workflow containers
EXITED_CONTAINERS=$(docker ps -a | grep ${DOCKER_IMAGE} | awk '{print $1}')
[ -n "${EXITED_CONTAINERS}" ] && echo "Cleaning up exited containers:" && docker rm -f ${EXITED_CONTAINERS}

# option checks
# TODO : Add server type check
# option checks
ENGINE_CMD+=" -e EXECUTION_CONTEXT=${EXECUTION_CONTEXT}"
if [ "${EXECUTION_CONTEXT}" == "local" ];then

  CPU_COUNT=$(nproc --all)
  if [[ "$CPU_COUNT" -eq 64 ]]; then
    ENGINE_CMD+=" -e CONFIG_FILE_PATH=${PHASE4_CONFIG_PATH}"
  else
    ENGINE_CMD+=" -e CONFIG_FILE_PATH=${PHASE3_CONFIG_PATH}"
  fi

  ENGINE_CMD+=" ${ENGINE_CMD_EDICO}"
  [ -z "${ANALYSIS_FOLDER}" ] && ANALYSIS_FOLDER="${ANALYSIS_FOLDER:-"/staging/${RUN_UID}"}"

else
 [ -z "${ANALYSIS_FOLDER}" ] && ANALYSIS_FOLDER="${ANALYSIS_FOLDER:-"/ephemeral/${RUN_UID}"}"
fi

mkdir -p "${ANALYSIS_FOLDER}"
INPUT_FILE="${ANALYSIS_FOLDER}/inputs.json"
RECEIPT="${ANALYSIS_FOLDER}/receipt"
checkDirectory "$ANALYSIS_FOLDER"

# Add the analysis subfolders
ENGINE_ANALYSIS_SUB_DIRS=" $ENGINE_BIND_PREFIX $ANALYSIS_FOLDER/work:/opt/illumina/work \
    $ENGINE_BIND_PREFIX $ANALYSIS_FOLDER/Results:/opt/illumina/Results \
    $ENGINE_BIND_PREFIX $ANALYSIS_FOLDER/errors:/opt/illumina/errors \
    $ENGINE_BIND_PREFIX $ANALYSIS_FOLDER/Logs_Intermediates:/opt/illumina/Logs_Intermediates \
    $ENGINE_BIND_PREFIX $ANALYSIS_FOLDER/.nextflow:/opt/illumina/.nextflow "
ENGINE_CMD+=" ${ENGINE_ANALYSIS_SUB_DIRS} "

# Create the sub directories under analysis folder
mkdir -p "$ANALYSIS_FOLDER/Results"
mkdir -p "$ANALYSIS_FOLDER/errors"
mkdir -p "$ANALYSIS_FOLDER/Logs_Intermediates"
mkdir -p "$ANALYSIS_FOLDER/.nextflow"
mkdir -p "$ANALYSIS_FOLDER/work"

# NOTE : THIS CAUSED THE PIPELINE TO FAIL by creating //.nextflow - permission denied
# Run as the specified USER_ID if provided. 
#if [[ -n "${USER_ID}" ]]; then 
#    ENGINE_CMD+=" --user=${USER_ID} "
#else
#    # Otherwise run as the current user if not root.
#    if [[ "$EUID" -ne 0 ]]; then
#        ENGINE_CMD+=" --user=$(id -u):$(id -g) "
#    fi
#fi

# Run the workflow as the specified USER_ID if provided.
if [[ -n "${USER_ID}" ]]; then
    echo "using specified user_id"
    ENGINE_CMD+=" -e HOST_USER_ID=${USER_ID} "
else
    # Otherwise run as the current user if not root.
    if [[ "$EUID" -ne 0 ]]; then
        echo "using assumed user_id"
        USER_ID=$(id -u)
        ENGINE_CMD+=" -e HOST_USER_ID=${USER_ID} "
        # Get the group id that owns docker.sock so that the container can align on that with the executing user.
        ENGINE_CMD+=" -e HOST_DOCKER_GROUP_ID=$(cut -d: -f3 < <(getent group $(stat -c "%G" /var/run/docker.sock)))"
    fi
fi

[ ! -z "${NO_REMOVE_CONTAINER}" ] || ENGINE_CMD+=" --rm"
[ ! -z "${DEV}" ] && ENGINE_CMD+=" -i  --entrypoint bash"

if [[ -z "${FASTQ_FOLDER}" ]] ; then 

    # verify analysis folder disk has minimum amount of free space
    echo "Checking disk space...";
    checkDiskSpace

fi

writeReceipt "--analysisFolder ${ANALYSIS_FOLDER}"
ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${ANALYSIS_FOLDER}:${ANALYSIS_FOLDER_IN_CONTAINER}${ENGINE_BIND_SUFFIX}"

[ ! -z "${NO_REMOVE_CONTAINER}" ] || ENGINE_CMD+=" --rm"
[ ! -z "${DEV}" ] && ENGINE_CMD+=" -i  --entrypoint bash"

# Start the input file
echo "{" > $INPUT_FILE

# manage the license for running in cloud
echo "Checking dragen license";
if [ ! -z "${LICENSE}" ]; then
    echo "${LICENSE}" > "${ANALYSIS_FOLDER}/dragen_license.txt"
    writeReceipt "--license" "${LICENSE}"
fi
writeInputFile "\"license_server\": \"${LICENSE}\","

echo "Checking resources folder";
[ -z "${RESOURCES_FOLDER}" ] && RESOURCES_FOLDER="${DEFAULT_RESOURCES_FOLDER}"
checkDirectory "${RESOURCES_FOLDER}"
writeReceipt "--resourcesFolder" "${RESOURCES_FOLDER}"
writeInputFile "\"resources_dir\": \"${RESOURCES_FOLDER_IN_CONTAINER}\","
checkFile "$RESOURCES_FOLDER/$RESOURCE_FILE_CHECK"
ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${RESOURCES_FOLDER}:${RESOURCES_FOLDER_IN_CONTAINER}${ENGINE_BIND_SUFFIX_RO}"

# handle samplepair flag checks.  do not show line when option is not present
docker run -v "${INTERMEDIATE_SAMPLE_IDS_FOLDER}":/opt/illumina --rm --entrypoint /bin/bash "${DOCKER_IMAGE}:${UNIFIED_VERSION}" -c "jq -rR 'split(\",\")' <<< '${SAMPLE_IDS}' > ${INTERMEDIATE_SAMPLE_IDS}"
SAMPLE_IDS=$(cat "${INTERMEDIATE_SAMPLE_ID_FILE}")
rm -f "${INTERMEDIATE_SAMPLE_ID_FILE}"

[ ! -z "${SAMPLE_IDS}" ] && writeInputFile "\"sample_ids\": ${SAMPLE_IDS},"

# handle fastq / runfolder / samplesheet checks
echo "Checking run folder..."
if [ ! -z "${RUN_FOLDER}" ]; then
  checkDirectoryAndPermissions "${RUN_FOLDER}"
  writeReceipt "--runFolder" "${RUN_FOLDER}"
  ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${RUN_FOLDER}:${RUN_FOLDER_IN_CONTAINER}${ENGINE_BIND_SUFFIX_RO} "
  SAMPLESHEET_SRC="${RUN_FOLDER}"

  checkFile "${RUN_FOLDER}/RunInfo.xml"
  checkFile "${RUN_FOLDER}/RunParameters.xml"
  [ ! -f "${RUN_FOLDER}/CopyComplete.txt" ] && echo "CopyComplete.txt file missing from run folder." && exit 13

  # Start from BCLs 
  checkDirectoryAndPermissions "${RUN_FOLDER}/Data/Intensities"
  checkDirectoryAndPermissions "${RUN_FOLDER}/InterOp"
  
  writeInputFile "\"run_folder\": \"${RUN_FOLDER_IN_CONTAINER}\","
fi

echo "Checking fastQ folder";
if [ ! -z "${FASTQ_FOLDER}" ]; then
  # Start from Fastqs
  checkDirectoryAndPermissions "${FASTQ_FOLDER}"
  writeReceipt "--fastqFolder" "${FASTQ_FOLDER}"
  ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${FASTQ_FOLDER}:${FASTQ_FOLDER_IN_CONTAINER}${ENGINE_BIND_SUFFIX_RO} "
  writeInputFile "\"fastq_folder\": \"${FASTQ_FOLDER_IN_CONTAINER}\","; #"\"TSO500ctDNA.fastqFolder\": \"${FASTQ_FOLDER_IN_CONTAINER}\","

  SAMPLESHEET_SRC="${FASTQ_FOLDER}"

fi

echo "Checking Samplesheet..."
# samplesheet.csv needs to reside in the run folder or fastq_folder, depending on which dir was specified by the user.
[[ -z "${SAMPLESHEET}" ]] && SAMPLESHEET="${SAMPLESHEET_SRC}/SampleSheet.csv"
checkFile "${SAMPLESHEET}"

# Copy samplesheet to analysis folder for logging
cp "${SAMPLESHEET}" "${ANALYSIS_FOLDER}";

writeReceipt  "--sampleSheet" "${SAMPLESHEET}"
writeInputFile "\"sample_sheet\": \"${SAMPLESHEET_IN_CONTAINER}\",";

ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${SAMPLESHEET}:${SAMPLESHEET_IN_CONTAINER}${ENGINE_BIND_SUFFIX_RO}"

writeInputFile "\"product_name\": \"${PRODUCT_NAME}\"," #"\"TSO500ctDNA.productName\": \"${PRODUCT_NAME}\","
writeInputFile "\"product_version\": \"${UNIFIED_VERSION}\"," #"\"TSO500ctDNA.productVersion\": \"${UNIFIED_VERSION}\""

# TODO : Remove for release, keep for dev debugging
# Handle first tile only
writeReceipt "--firstTileOnly" "${FIRST_TILE_ONLY}";
writeInputFile "\"first_tile_only\": \"${FIRST_TILE_ONLY}\"";

# close the input file footer
echo "}" >> "${INPUT_FILE}"


# add input JSON file to args
ENGINE_CMD+=" ${ENGINE_BIND_PREFIX} ${INPUT_FILE}:/opt/illumina/params.json "

# create the full command to run.
ENGINE_CMD+=" ${ENGINE_CMD_SUFFIX}"

# runtime receipt details
writeReceipt Docker `docker version`
writeReceipt Dragen `/opt/edico/bin/dragen --version 2>&1`
writeReceipt System `uname -a`
writeReceipt "Local Disks" `df -hl`
writeReceipt "Run Command" "${ENGINE_CMD}"

# Show where the analysis output will be
echo
echo "Analysis output will be written to: ${ANALYSIS_FOLDER}"
sleep 2

echo
echo "Final $INPUT_FILE contents:"
cat "${INPUT_FILE}"
echo
sleep 2

echo -e "Preparing to run: ${ENGINE_CMD}"
echo
sleep 2

/opt/edico/bin/dragen_reset
trap cleanupOnSignal SIGINT SIGTERM
set -e
${ENGINE_CMD} | tee -a  ${ANALYSIS_FOLDER}/analysis.log
sleep 2;

echo
echo
echo "${PRODUCT_NAME} completed SUCCESSFULLY!"
echo "Analysis output has been written to: ${ANALYSIS_FOLDER}"
